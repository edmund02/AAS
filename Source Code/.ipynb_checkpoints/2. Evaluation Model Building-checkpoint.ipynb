{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: split data\n",
      "Done: Fit SVC\n",
      "Done: Predict\n",
      "\n",
      "Train Accuracy:  0.8293236495687698\n",
      "Test Accuracy:  0.8230088495575221 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.46      0.58       110\n",
      "           2       0.83      0.96      0.89      1114\n",
      "           3       0.74      0.37      0.49       245\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1469\n",
      "   macro avg       0.78      0.60      0.65      1469\n",
      "weighted avg       0.81      0.82      0.80      1469\n",
      "\n",
      "[0.8095238095238095, 0.8299319727891157, 0.8180272108843537, 0.858843537414966, 0.8741496598639455, 0.868824531516184, 0.7529812606473595, 0.6899488926746167, 0.7649063032367973, 0.7853492333901193]\n",
      "0.8052486411941269\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('essaywithfeature (2).csv', encoding='cp1252')\n",
    "X = dataset.iloc[:, 3:17].values\n",
    "y = dataset.iloc[:, 17].values\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# ros = RandomOverSampler(random_state=1)\n",
    "# X,y = ros.fit_resample(X,y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection  import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# ros = RandomOverSampler(random_state=1)\n",
    "# X_train,y_train = ros.fit_resample(X_train,y_train)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(\"Done: split data\")\n",
    "\n",
    "# Fitting Kernel SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 1, decision_function_shape = 'ovo', C = 1, gamma = 0.1)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(\"Done: Fit SVC\")\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_test = classifier.predict(X_test)\n",
    "y_pred_train = classifier.predict(X_train)\n",
    "print(\"Done: Predict\\n\")\n",
    "\n",
    "#Result\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Train Accuracy: ',accuracy_score(y_train, y_pred_train,))\n",
    "print('Test Accuracy: ',accuracy_score(y_test, y_pred_test,),'\\n')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_report = classification_report(y_test, y_pred_test, )\n",
    "print(classifier_report)\n",
    "\n",
    "#cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "cv_stf = KFold(n_splits=10)\n",
    "test_acc = []\n",
    "for train_index, test_index in cv_stf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "#     from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "#     oversample = RandomOverSampler()\n",
    "#     X_train, y_train = oversample.fit_sample(X_train, y_train)\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    # Predicting the Test set results\n",
    "    y_pred_test = classifier.predict(X_test)\n",
    "    test_acc.append(accuracy_score(y_test, y_pred_test,))\n",
    "\n",
    "print(test_acc)\n",
    "print(sum(test_acc)/10)\n",
    "\n",
    "# with open('classifierml.pkl', 'wb') as file:  \n",
    "#     pickle.dump(classifier, file)\n",
    "# with open('scalerml.sav', 'wb') as file:  \n",
    "#     pickle.dump(sc.transform, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6823829787234043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.41      0.28       440\n",
      "           2       0.81      0.77      0.79      4456\n",
      "           3       0.50      0.41      0.45       979\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      5875\n",
      "   macro avg       0.51      0.53      0.51      5875\n",
      "weighted avg       0.71      0.68      0.69      5875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#non-machine learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('essaywithfeature (2).csv', encoding='cp1252')\n",
    "X = dataset.iloc[:, 3:17].values\n",
    "y = dataset.iloc[:, 17].values\n",
    "\n",
    "\n",
    "mean_cut = [[233.19, 405.07], [13.13, 25.28], [4.08, 4.24], [18.69, 38.13], [22.58, 17.53], \n",
    "                [6.31, 11.15], [102.2, 167.97], [44.59, 79.21], [7.96, 17.07], [15.04, 27.24], [49.42, 83.68], \n",
    "                [13.02, 23.37], [0.8, 0.76], [12.93, 16.06]]\n",
    "median_cut = [[212.75, 391.0], [12.0, 24.5], [4.11, 4.27], [17.0, 38.5], [17.71, 16.2], [5.5, 10.5], \n",
    "            [97.0, 165.5], [41.5, 81.0], [5.0, 13.5], [13.5, 26.5], [44.5, 78.5], [11.0, 21.0], \n",
    "            [0.85, 0.81], [10.0, 14.0]]\n",
    "ratio_cut = [[83.31, 886.53], [8.11, 80.17], [3.24, 4.96], [11.76, 130.84], [247.15, 24.81], [29.17, 2.62], \n",
    "            [37.33, 374.85], [20.3, 225.84], [24.42, 271.68], [6.07, 67.5], [20.47, 217.67], [6.52, 72.5], \n",
    "            [0.07, 0.83], [127.5, 11.46]]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def nonmlScoring (cutter, ft, y):\n",
    "    y_pred = []\n",
    "    for i in range(len(ft)):\n",
    "        temp=[]\n",
    "        for j in range(len(ft[i])):\n",
    "            \n",
    "            if j in (4,5,13) :\n",
    "                \n",
    "                if ft[i][j] > cutter[j][0] :\n",
    "                    temp.append(1)\n",
    "                elif ft[i][j] <= cutter[j][0] and ft[i][j] > cutter[j][1] :\n",
    "                    temp.append(2)\n",
    "                else:\n",
    "                    temp.append(3)\n",
    "                    \n",
    "            else:\n",
    "        \n",
    "                if ft[i][j] < cutter[j][0] :\n",
    "                    temp.append(1)\n",
    "                elif ft[i][j] >= cutter[j][0] and ft[i][j] < cutter[j][1] :\n",
    "                    temp.append(2)\n",
    "                else:\n",
    "                    temp.append(3)\n",
    "            \n",
    "        y_pred.append(round(sum(temp)/14))\n",
    "        \n",
    "    print('Accuracy: ',accuracy_score(y, y_pred))\n",
    "    return(y_pred)\n",
    "\n",
    "nonml_y = nonmlScoring(mean_cut,X,y)      \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_report = classification_report(y, nonml_y, )\n",
    "print(classifier_report)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: split data\n",
      "Done: Fit SVC\n",
      "Done: Predict\n",
      "\n",
      "Nonml Accuracy:  0.675289312457454 \n",
      "\n",
      "Test Accuracy: 0.8230088495575221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.46      0.58       110\n",
      "           2       0.83      0.96      0.89      1114\n",
      "           3       0.74      0.37      0.49       245\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1469\n",
      "   macro avg       0.78      0.60      0.65      1469\n",
      "weighted avg       0.81      0.82      0.80      1469\n",
      "\n",
      "Test Accuracy: 0.8230088495575221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.46      0.58       110\n",
      "           2       0.83      0.96      0.89      1114\n",
      "           3       0.74      0.37      0.49       245\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1469\n",
      "   macro avg       0.78      0.60      0.65      1469\n",
      "weighted avg       0.81      0.82      0.80      1469\n",
      "\n",
      "Test Accuracy: 0.8230088495575221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.46      0.58       110\n",
      "           2       0.83      0.96      0.89      1114\n",
      "           3       0.74      0.37      0.49       245\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1469\n",
      "   macro avg       0.78      0.60      0.65      1469\n",
      "weighted avg       0.81      0.82      0.80      1469\n",
      "\n",
      "Test Accuracy: 0.8230088495575221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.46      0.58       110\n",
      "           2       0.83      0.96      0.89      1114\n",
      "           3       0.74      0.37      0.49       245\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1469\n",
      "   macro avg       0.78      0.60      0.65      1469\n",
      "weighted avg       0.81      0.82      0.80      1469\n",
      "\n",
      "Test Accuracy: 0.7991831177671885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.14      0.23       110\n",
      "           2       0.80      0.98      0.88      1114\n",
      "           3       0.77      0.28      0.41       245\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1469\n",
      "   macro avg       0.80      0.47      0.51      1469\n",
      "weighted avg       0.80      0.80      0.75      1469\n",
      "\n",
      "Test Accuracy: 0.675289312457454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      0.36      0.25       110\n",
      "           2       0.81      0.76      0.78      1114\n",
      "           3       0.51      0.42      0.46       245\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1469\n",
      "   macro avg       0.50      0.52      0.50      1469\n",
      "weighted avg       0.71      0.68      0.69      1469\n",
      "\n",
      "Test Accuracy: 0.675289312457454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      0.36      0.25       110\n",
      "           2       0.81      0.76      0.78      1114\n",
      "           3       0.51      0.42      0.46       245\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1469\n",
      "   macro avg       0.50      0.52      0.50      1469\n",
      "weighted avg       0.71      0.68      0.69      1469\n",
      "\n",
      "Test Accuracy: 0.675289312457454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      0.36      0.25       110\n",
      "           2       0.81      0.76      0.78      1114\n",
      "           3       0.51      0.42      0.46       245\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1469\n",
      "   macro avg       0.50      0.52      0.50      1469\n",
      "weighted avg       0.71      0.68      0.69      1469\n",
      "\n",
      "Test Accuracy: 0.675289312457454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      0.36      0.25       110\n",
      "           2       0.81      0.76      0.78      1114\n",
      "           3       0.51      0.42      0.46       245\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1469\n",
      "   macro avg       0.50      0.52      0.50      1469\n",
      "weighted avg       0.71      0.68      0.69      1469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#combine 1\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('essaywithfeature (2).csv', encoding='cp1252')\n",
    "X = dataset.iloc[:, 3:17].values\n",
    "y = dataset.iloc[:, 17].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection  import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)\n",
    "X_testc2=X_test.tolist()\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(\"Done: split data\")\n",
    "\n",
    "# Fitting Kernel SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 1, decision_function_shape = 'ovo', C = 1, degree = 4, gamma = 0.1)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Done: Fit SVC\")\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_test = classifier.predict(X_test)\n",
    "print(\"Done: Predict\\n\")\n",
    "\n",
    "\n",
    "cut = [[233.19, 405.07], [13.13, 25.28], [4.08, 4.24], [18.69, 38.13], [22.58, 17.53], [6.31, 11.15], \n",
    "             [102.2, 167.97], [44.59, 79.21], [7.96, 17.07], [15.04, 27.24], [49.42, 83.68], [13.02, 23.37], \n",
    "             [0.8, 0.76], [12.93, 16.06]]\n",
    "\n",
    "\n",
    "def nonmlScoring (cutter, ft, y):\n",
    "    y_pred = []\n",
    "    for i in range(len(ft)):\n",
    "        temp=[]\n",
    "        for j in range(len(ft[i])):\n",
    "            \n",
    "            if j in (4,5,13) :\n",
    "                \n",
    "                if ft[i][j] > cutter[j][0] :\n",
    "                    temp.append(1)\n",
    "                elif ft[i][j] <= cutter[j][0] and ft[i][j] > cutter[j][1] :\n",
    "                    temp.append(2)\n",
    "                else:\n",
    "                    temp.append(3)\n",
    "                    \n",
    "            else:\n",
    "        \n",
    "                if ft[i][j] < cutter[j][0] :\n",
    "                    temp.append(1)\n",
    "                elif ft[i][j] >= cutter[j][0] and ft[i][j] < cutter[j][1] :\n",
    "                    temp.append(2)\n",
    "                else:\n",
    "                    temp.append(3)\n",
    "            \n",
    "        y_pred.append(round(sum(temp)/14))\n",
    "        \n",
    "    return(y_pred)\n",
    "\n",
    "nonml_y = nonmlScoring(cut,X_testc2,y_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Nonml Accuracy: ',accuracy_score(y_test, nonml_y,),'\\n')\n",
    "\n",
    "def combine2(ml, nonml, w, y):\n",
    "    y_c2 = []\n",
    "    for i in range(len(w)):\n",
    "        temp = []\n",
    "        for j in range(len(ml)):\n",
    "            temp.append(round((ml[j]*w[i][0]+nonml[j]*w[i][1])/sum(w[i])))\n",
    "    \n",
    "        y_c2.append(temp)\n",
    "    return(y_c2)\n",
    "\n",
    "weight=[[2,1],[1.8,1],[1.5,1],[1.3,1],[1,1],[1,1.3],[1,1.5],[1,1.8],[1,2]]\n",
    "y_c2 = combine2(y_pred_test, nonml_y, weight, y_test )\n",
    "\n",
    "for i in y_c2:\n",
    "    print(\"Test Accuracy:\", accuracy_score(y_test, i))\n",
    "    from sklearn.metrics import classification_report\n",
    "    classifier_report = classification_report(y_test, i, )\n",
    "    print(classifier_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: split data\n",
      "Done: Fit SVC\n",
      "Done: Predict\n",
      "\n",
      "Train Accuracy:  0.8361325465274626\n",
      "Test Accuracy:  0.8250510551395507 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.49      0.60       110\n",
      "           2       0.84      0.96      0.89      1114\n",
      "           3       0.73      0.38      0.50       245\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1469\n",
      "   macro avg       0.78      0.61      0.67      1469\n",
      "weighted avg       0.82      0.83      0.81      1469\n",
      "\n",
      "[0.8078231292517006, 0.8350340136054422, 0.8112244897959183, 0.858843537414966, 0.8758503401360545, 0.8671209540034072, 0.7529812606473595, 0.6899488926746167, 0.7666098807495741, 0.7819420783645656]\n",
      "0.8047378576643606\n"
     ]
    }
   ],
   "source": [
    "#combine 2\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('essaywithfeaturec2.csv', encoding='cp1252')\n",
    "X = dataset.iloc[:, 3:18].values\n",
    "y = dataset.iloc[:, 18].values\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# ros = RandomOverSampler()\n",
    "# X,y = ros.fit_resample(X,y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection  import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# X_test, y_test = ros.fit_resample(X_test,y_test)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(\"Done: split data\")\n",
    "\n",
    "# Fitting Kernel SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 1, decision_function_shape = 'ovo', C = 1, gamma = 0.1)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Done: Fit SVC\")\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_test = classifier.predict(X_test)\n",
    "y_pred_train = classifier.predict(X_train)\n",
    "print(\"Done: Predict\\n\")\n",
    "\n",
    "#Result\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Train Accuracy: ',accuracy_score(y_train, y_pred_train,))\n",
    "print('Test Accuracy: ',accuracy_score(y_test, y_pred_test,),'\\n')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_report = classification_report(y_test, y_pred_test, )\n",
    "print(classifier_report)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "cv_stf = KFold(n_splits=10)\n",
    "test_acc = []\n",
    "for train_index, test_index in cv_stf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "#     from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "#     oversample = RandomOverSampler()\n",
    "#     X_train, y_train = oversample.fit_sample(X, y)\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "#     print(\"Done: Fit SVC\")\n",
    "    # Predicting the Test set results\n",
    "    y_pred_test = classifier.predict(X_test)\n",
    "    test_acc.append(accuracy_score(y_test, y_pred_test,))\n",
    "\n",
    "print(test_acc)\n",
    "print(sum(test_acc)/10)\n",
    "\n",
    "# with open('classifierc2.pkl', 'wb') as file:  \n",
    "#     pickle.dump(classifier, file)\n",
    "# with open('scalerc2.sav', 'wb') as file:  \n",
    "#     pickle.dump(sc.transform, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
