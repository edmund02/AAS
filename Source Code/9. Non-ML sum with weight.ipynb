{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('essaywithfeature (3).csv', encoding='cp1252')\n",
    "X = dataset.iloc[:, 3:17].values\n",
    "y = dataset.iloc[:, 17].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "# from sklearn.model_selection  import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)\n",
    "\n",
    "# print(\"Done: split data\")\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE, ADASYN\n",
    "# smote = SMOTE()\n",
    "# X_train, y_train = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X = sc.fit_transform(X)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "X = mms.fit_transform(X)\n",
    "# X_test = mms.transform(X_test)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0\n"
     ]
    }
   ],
   "source": [
    "min1=0\n",
    "max1=0\n",
    "for i in X :\n",
    "    for j in i :\n",
    "        if j>max1 :\n",
    "            max1 =j\n",
    "        if j< min1:\n",
    "            min1=j\n",
    "\n",
    "print(min1,max1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\"word_count\", <br>\n",
    "2\"sent_count\", <br>\n",
    "3\"ave_word_length\",<br> \n",
    "4\"long_word_count\"<br>\n",
    "5, \"ave_sent_length\", <br>\n",
    "6\"long_sent_count\",  <br>\n",
    "7\"unique_word_count\", <br>\n",
    "8\"noun_count\", <br>\n",
    "9\"propernoun_count\",<br> \n",
    "10\"adj_count\",<br>\n",
    "11 \"verb_count\", <br>\n",
    "12\"adverb_count\", <br>\n",
    "13\"tense_ratio\", <br>\n",
    "14\"error_count\"<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #assign weight\n",
    "\n",
    "weight1 = [9,8,3,5,2,1,10,4,4,4,4,4,7,6]\n",
    "# # weight1 = [0.10,0.10,0.055,0.10,0.015,0.055,0.10,0.055,0.055,0.055,0.055,0.055,0.10,0.10]\n",
    "# weight2 = [14,12,10,9,8,1,13,6,5,4,7,3,11,2]\n",
    "\n",
    "# X_train1 = []\n",
    "# X_test1 = []\n",
    "# X_train2 = []\n",
    "# X_test2 = []\n",
    "\n",
    "X = np.multiply(X,weight1)\n",
    "# X_test = np.multiply(X_test,weight1)\n",
    "# X_train2 = np.multiply(X_train,weight2)\n",
    "# X_test2 = np.multiply(X_test,weight2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.999999999999998\n"
     ]
    }
   ],
   "source": [
    "min1=0\n",
    "max1=0\n",
    "for i in X :\n",
    "    for j in i :\n",
    "        if j>max1 :\n",
    "            max1 =j\n",
    "        if j< min1:\n",
    "            min1=j\n",
    "\n",
    "print(min1,max1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.953070759726472 52.933274457465906\n",
      "52.9\n"
     ]
    }
   ],
   "source": [
    "X_sum = []\n",
    "\n",
    "for i in X :\n",
    "    X_sum.append(sum(i))\n",
    "\n",
    "cut1 =[] \n",
    "cut1.append(round(min(X_sum),1))\n",
    "\n",
    "print(min(X_sum),max(X_sum))\n",
    "\n",
    "c = 0\n",
    "while (True):\n",
    "    if cut1[c] > max(X_sum):\n",
    "        break\n",
    "    cut1.append(round(cut1[c]+0.1,1))\n",
    "#     print(cut1[c])\n",
    "    c +=1\n",
    "\n",
    "del cut1[-1]\n",
    "print(cut1[len(cut1)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96580"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = []\n",
    "for i in range(len(cut1)) :\n",
    "    for j in range(len(cut1)) :\n",
    "        if cut1[j]<=cut1[i]:\n",
    "            continue    \n",
    "        splitter.append([cut1[i],cut1[j]])\n",
    "#         if len(splitter) % 10000 == 0 :\n",
    "#             print(len(splitter))\n",
    "len(splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n",
      "Done\n",
      "Accuracy:  0.7617021276595745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.07      1.00      0.14       440\n",
      "           2       0.00      0.00      0.00      4456\n",
      "           3       1.00      0.00      0.00       979\n",
      "\n",
      "   micro avg       0.08      0.08      0.08      5875\n",
      "   macro avg       0.36      0.33      0.05      5875\n",
      "weighted avg       0.17      0.08      0.01      5875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edmund\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "\n",
    "print(\"Started\")\n",
    "\n",
    "for i in splitter :\n",
    "    y_pred = []\n",
    "    for x in X_sum :\n",
    "        if x < i[0] :\n",
    "            y_pred.append(1)\n",
    "        elif x >= i[0] and x < i[1] :\n",
    "            y_pred.append(2)\n",
    "        else :\n",
    "            y_pred.append(3) \n",
    "    acc.append(accuracy_score(y, y_pred))\n",
    "\n",
    "#     if len(acc) % 5000 == 0 :\n",
    "#         print(len(acc))\n",
    "\n",
    "print(\"Done\")     \n",
    "        \n",
    "index = acc.index(max(acc))\n",
    "print('Accuracy: ',max(acc))\n",
    "# print(splitter[index])\n",
    "split1=splitter[index][0]\n",
    "split2=splitter[index][1]\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_report = classification_report(y, y_pred)\n",
    "print(classifier_report)\n",
    "\n",
    "a1=0\n",
    "a3=0\n",
    "for i in y_pred:\n",
    "    if i==1:\n",
    "        a1+=1\n",
    "    elif i==3:\n",
    "        a3+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7617021276595745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.07      1.00      0.14       440\n",
      "           2       0.00      0.00      0.00      4456\n",
      "           3       1.00      0.00      0.00       979\n",
      "\n",
      "   micro avg       0.08      0.08      0.08      5875\n",
      "   macro avg       0.36      0.33      0.05      5875\n",
      "weighted avg       0.17      0.08      0.01      5875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edmund\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ',max(acc))\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_report = classification_report(y, y_pred)\n",
    "print(classifier_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Train Accuracy:  0.7617021276595745\n",
      "Test Accuracy:  0.7617021276595745 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.00      0.01       440\n",
      "           2       0.77      0.99      0.86      4456\n",
      "           3       0.57      0.07      0.13       979\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      5875\n",
      "   macro avg       0.78      0.36      0.33      5875\n",
      "weighted avg       0.75      0.76      0.68      5875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_sum = [sum(i) for i in X]\n",
    "\n",
    "y_pred = []\n",
    "for i in X_test_sum :\n",
    "    if i < split1 :\n",
    "        y_pred.append(1)\n",
    "    elif i>= split1 and i < split2 :\n",
    "        y_pred.append(2)\n",
    "    else :\n",
    "        y_pred.append(3)\n",
    "\n",
    "print('Best Train Accuracy: ',max(acc))\n",
    "print('Test Accuracy: ',accuracy_score(y, y_pred,),'\\n')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_report = classification_report(y, y_pred)\n",
    "print(classifier_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
